# Running a linear regression analysis

There are two quotes worth mentioning here.

Let no man ignorant of geometry enter - Sign over Plato’s Academy in Athens

Peggy Sue: Well, Mr Snelgrove, I happen to know that in the future I will not have the slightest use for algebra, and I speak from experience.

In my talks, I often ask the question, did you like High School Algebra. I get a mix of responses: some people loved it, some hated it, but most were indifferent. Fair enough, but if you want to run a linear regression analysis, you can't be indifferent. If nothing else, you have to remember the formula you learned in algebra for a straight line.

$y = mx + b$

The slope, m, represents the change in y divided by the change in x. The intercept, b, represents where the line crosses the y-axis.

The linear regression formula is a bit different.

$\hat{y}_i=\hat\beta_0+\hat\beta_1 X_i$

where the slope, $\hat\beta_1$ represents the estimated average change in Y when X increases by one unit and the intercept, $\hat\beta_0$, represents the estimated average value of Y when X equals zero.

## Step 1: Plot your data

I've always loved linear regression because it is so visual. You learn a lot before you compute any statistics by looking at graphs.

![](../images/figure-11-01.png "Scatterplot showing a strong linear relationship")

I added the trend line. You should try to eyeball the slope and intercept from your graph. You want to see if these values pass the "smell test." Do they seem reasonable or is something a bit fishy and warrants further investigation.

Here is how you calculate the slope. A thousand square foot house is predicted to sell for about 70 thousand dollars. A three thousand square foot house is predicted to sell for about 190 thousand dollars. These are just rough estimates. Don't worry if you don't get them quite right.

The slope is the change in Y (120 thousand dollars) divided by the change in X (2 thousand square feet), which produces a rough estimate of your slope, 60 dollars per square foot. That passes the smell test. It seems eminently reasonable, especially considering that these are 1993 houses.

To calculate the intercept, you need to redraw the graph so that you can read the prediction at x=0. Here's what that graph looks like. I extended the line beyond the range of the data, which is a something that you should do with great caution.

![](../images/figure-11-02.png)

The intercept appears to be just a tad above zero. Call it five thousand dollars. Now does it make sense to pay five thousand dollars for a house of zero square feet? You might argue that the five thousand dollars represents the estimated average price for an empty lot, perhaps. Perhaps not. If you are a bit skeptical of this interpretation, you are probably justified in that skepticism. It is quite a bit of an extrapolation.

The importance of the eyeball estimates is that they greatly reduce the fear and intimidation that you might feel when you actually run your regression analysis. You will be looking for two friends, the slope of around 60 and the intercept of around five thousand. When you see those friends in your regression table, you will get some reassurance that you are doing things properly.

Now if your regression model includes categorical variables, display them using boxplots. You might suspect that custom built houses will be a bit pricier, and looking at the boxplot, you'd be right!

![](../images/figure-11-03.png)

I added the means (small plus signs) and a line connecting them to this boxplot. The estimated average price of a regular home appears to be around 95 thousand dollars. The average price for a custom-built house is around 145 thousand dollars, about 50 thousand dollars more. When you run the regression model predicting price from the custom-built indicator, look for two friends, a slope of 50 thousand dollars and an intercept of 95 thousand dollars.

If you plan to look at the joint effects of size and custom-built, take some time to evaluate how these two independent variables relate to one another. A boxplot works well here.

![](../images/figure-11-04.png)

This box plot shows an interesting pattern that you probably were expecting. Custom-built houses are also bigger houses. The two independent variables are positively correlated. This is not a fatal problem, but you should use some care when trying to disentangle the individual effects of each variable.

Now if you have a lot of independent variables (five or more is a lot), you may not have the time and luxury of looking at every interrelationship among your independent variables. A correlation matrix might still be useful. Here is the correlation matrix between the two independent variables and the dependent variable. I am not rounding the values here, but you should round to two significant figures in any report that you prepare.


Table 11-1. Correlations

{{< include ../images/table_11_01.txt >}}

The correlations are all large and positive, which passes the smell test.

## Step 2: Compute a simple model

There are two types of models, crude models and adjusted models. A crude model looks at how a single factor affects your outcome measure and ignores potential covariates. An adjusted model incorporates these potential covariates. Start with a crude model. It’s simpler and it helps you to get a quick overview of how things are panning out. Then continue by making adjustments for important confounders.

A crude model for comparing duration of breast feeding to feeding group would be a t-test. I prefer

however
to present a general linear model because it provides a unifying framework for diverse statistical methods like analysis of variance
analysis of covariance, multiple linear regression
repeated measures designs
and t-tests.
Shown below is the table of tests from the general linear model procedure.



The general linear model uses an F test instead of the t test

but in this context
these two tests are mathematically equivalent. The p-value for comparing feeding groups is .001
which indicates a significant difference between the two groups.
The general linear model also has a table of estimates

which is presented below.


The intercept represents the average duration of breast feeding for the NG tube group. We see that the average duration is 20 weeks for the NG tube group. The (FEED_TYP=1) term is an estimate of how much the average duration changes when we move from the NG tube group to the bottle group. We see that the bottle group has an average duration that is 7 weeks shorter.

Shown below is a table of means from the general linear model.



We see that the difference between the two means is roughly 7 weeks, which confirms the results shown previously.

## Step 3: Compute an adjusted model

but could some of all of this difference be due to the fact that the NG tube group had older mothers? To answer this
we need to fit an adjusted model.
Shown below is the table of tests for a general linear model that includes mother’s age in the model.


This table shows that the effect of bottle feeding is to decrease duration of breast feeding by about six weeks

after adjusting for mother’s age. Each year that a mother is older increase the duration of breast feeding by a quarter of a week.
A previous descriptive analysis of this data revealed that the average age for mothers in the treatment group is 29 years and the average age for mothers in the control group is 25 years. When you see a discrepancy like this in an important covariate

you need to assess whether the four year gap in average ages could account for part or all of the effect of the treatment group.
This analysis shows that the four year gap only accounts for a small portion of the difference. Since each year of age changes the duration by a quarter week

this means that the difference between mother’s ages acounts for just one week in the 7 week difference we saw in the crude model.
Shown below is the table of means.

This table now adjusts for mother’s age. The mean for the bottle fed group is adjusted upward to what it would be if the average age of the mothers in this group were 27 rather than 25. The mean for the NG tube group is adjusted downward to what it would be if the average age were 27 instead of 29. Note that the adjusted mean duration is half a week higher than the crude mean duration in the bottle group and that the adjusted mean duration is half a week lower than the crude mean duration for the NG tube group. This confirms that the difference between the two feeding groups is roughly 6 weeks

after adjusting for mother’s age. This is one week less than the crude model.
This is not the final model. We should examine the effect of delivery type and account for the fact that we have some data on twins. I hope, though

that this presentation gives you a general idea of what crude and adjusted models are.


## The fly in the ointment: clustered data

Add text.

Linear regression models provide a good way to examine how various factors influence a continuous outcome measure. There are three steps in a typical linear regression analysis.

Fit a crude model
Fit an adjusted model
Analyze predicted values and residuals
These steps may not be appropriate for every linear regression analysis, but they do serve as a general guideline. In this presentation

you will see these steps applied to data from a breast feeding study
using SPSS software.
This presentation can only give the briefest introduction to this area. When I have time

I hope to add additional web pages to provide a more thorough approach to this topic.
**Step 1

Fit a crude model**
**Step 2

Fit an adjusted model**
The previous model was a crude model. We see a seven week difference between the two groups




The p-value for feeding group is .009

which is still significant
even after adjusting for the effect of mother’s age.
Shown below is the table of estimates from the same general linear model.






**Step 3

Analyze predicted values and residuals**.
A regression model gives you an equation that you can use to compute predicted values and residuals. In the regression model with mother’s age and feeding type

the equation (with a bit of rounding) is
age_stop = 13 + 0.25 * age - 6 * feed_typ,

where feed_typ=1 if control

0 if treatment.
So

for example
if you recruited a mother into the treatment group and she was 30 years old
you would predict the duration of breast feeding to be
predicted age_stop = 13 + 0.25 * 30 - 6 * 0 = 20.5 weeks.

If you recruited a mother into the treatment group and she was 19 years old

you would predict the duration of breast feeding to be
predicted age_stop = 13 + 0.25 * 19 - 6 * 0 = 17.75 weeks.

If you recruited a mother into the control group and she was 37 years old

you would predict the duration of breast feeding to be
predicted age_stop = 13 + 0.25 * 37 - 6 * 1 = 16.25 weeks.

Now it turns out that the first three rows of your data set correspond to the three scenarios described above. The actual values we observed were 30 weeks

4 weeks
and 12 weeks.
The residual is the difference between what we observed in the data and what the regression model would have predicted. For the first mother in the sample

you can observe that there are 30 weeks of breast feeding, but the model predicted much less
20.5 weeks. You can compute
residual = 30 - 22.5 = 7.5.

When the residual is positive

your regression model has under-predicted the outcome. With the second mother
your regression model has over-predicted the outcome. The observed value is 4 and the predicted value is 17.75. So you can compute
residual = 4 - 17.75 = -13.75.

This residual is negative. For the third mother

the residual is also negative.
residual = 12 - 16.25 = -4.25.

Most statistical models require certain assumptions to be made about your data. These assumptions can be examined using residuals. If your model is good

the residuals show a random featureless scatter. If instead
they show a systematic trend or pattern
then you can improve by incorporating that trend or pattern into your model.
The simplest plot is a plot of predicted values versus residuals (shown below).



The relatively random scatter of data values provides us with confidence in the assumptions of the linear model. There is no obvious trend or pattern in this plot.

I also looked at the residuals versus the feeding groups and versus mother’s age. Both showed no systematic trend or pattern (graphs not shown).

The following plot examines normality of the residuals.



The curved line indicates a non-normal distribution. Further investigation would identify that this distribution is rectangular: it has a sharp lower and upper bound that differs from a bell shaped curve. The design of this study produces these limits because the age at which the mother stops breast feeding can’t be shorter than 0 weeks and it can’t be longer than the duration of the study (roughly 6 months). In practice

this type of non-normality is not a serious problem.
Summary

There are three steps in a typical linear regression model analysis.

Fit a crude model.
Fit an adjusted model.
Examine predicted values and residuals.
You can find an earlier version of this page on my original website.

Excluding direct quotes from outside sources, all text is in the public domain. Images are copyrighted unless noted 

## Bibliography

UCLA Statistical Consulting Group. Regression Analysis | SAS Annotated Output. Available in [html format][ucla-nodate].

Steve Simon. Steps in a typical linear regression analysis. PMean blog, 1999-09-21. Available in [html format][simon-1999].

Steve Simon. Interpreting coefficients in a linear regression model. PMean blog, 2002-06-24. Available in [html format][simon-2002]

Steve Simon. Building a complex model. PMean blog, 2003-04-23. Available in [html format][simon-2003].

Steve Simon. Joke about the dangers of extrapolation. Pmean blog, 2021-11-27. Available in [html format][simon-2021].


[simon-1999]: http://new.pmean.com/steps-in-linear-regression/
[simon-2002]: http://new.pmean.com/intepreting-linear-regression-coefficients/
[simon-2003]: http://new.pmean.com/building-complex-models/
[simon-2021]: http://new.pmean.com/extrapolation-joke/
[ucla-nodate]: https://stats.oarc.ucla.edu/sas/output/regression-analysis/
